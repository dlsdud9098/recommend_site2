from playwright.sync_api import sync_playwright
import json
import requests
import time
import os
import json
from fake_useragent import UserAgent
from tqdm import tqdm
from tqdm.asyncio import tqdm_asyncio
from playwright.async_api import async_playwright
import random
import asyncio
import pandas as pd
from itertools import chain

def get_session_info():
    """í˜ì´ì§€ ë°©ë¬¸í•´ì„œ ì„¸ì…˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        
        page.goto('https://page.kakao.com/menu/10011/screen/84')
        page.wait_for_load_state('networkidle')
        
        cookies = page.context.cookies()
        user_agent = page.evaluate('navigator.userAgent')
        
        browser.close()
    
    return cookies, user_agent

def crawl_novels_with_requests():
    """requestsë¥¼ ì‚¬ìš©í•´ì„œ ì§ì ‘ GraphQL API í˜¸ì¶œ"""
    print("ì„¸ì…˜ ì •ë³´ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
    cookies, user_agent = get_session_info()
    
    session = requests.Session()
    
    # ì¿ í‚¤ ì„¤ì •
    for cookie in cookies:
        session.cookies.set(cookie['name'], cookie['value'])
    
    headers = {
        'User-Agent': user_agent,
        'Content-Type': 'application/json',
        'Accept': 'application/json',
        'Referer': 'https://page.kakao.com/',
        'Origin': 'https://page.kakao.com',
        'sec-ch-ua': '"Not.A/Brand";v="99", "Chromium";v="136"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"Linux"'
    }
    
    # GraphQL ì¿¼ë¦¬ (ì›ë³¸ì—ì„œ ì¶”ì¶œ)
    query = """
    query staticLandingGenreSection($sectionId: ID!, $param: StaticLandingGenreParamInput!) {
      staticLandingGenreSection(sectionId: $sectionId, param: $param) {
        ...Section
      }
    }
    
    fragment Section on Section {
      id
      uid
      type
      title
      ... on StaticLandingGenreSection {
        isEnd
        totalCount
        param {
          categoryUid
          subcategory {
            name
            param
          }
          sortType {
            name
            param
          }
          page
          isComplete
          screenUid
        }
      }
      groups {
        ...Group
      }
    }
    
    fragment Group on Group {
      id
      type
      dataKey
      items {
        ...Item
      }
    }
    
    fragment Item on Item {
      id
      type
      ...PosterViewItem
      ...CardViewItem
    }
    
    fragment PosterViewItem on PosterViewItem {
      id
      type
      scheme
      title
      altText
      thumbnail
      badgeList
      ageGradeBadge
      statusBadge
      subtitleList
      rank
      rankVariation
      ageGrade
      selfCensorship
      seriesId
      showDimmedThumbnail
      discountRate
      discountRateText
    }
    
    fragment CardViewItem on CardViewItem {
      title
      altText
      thumbnail
      scheme
      badgeList
      ageGradeBadge
      statusBadge
      ageGrade
      selfCensorship
      subtitleList
      caption
      rank
      rankVariation
      isEventBanner
      categoryType
      discountRate
      discountRateText
      backgroundColor
      isBook
      isLegacy
    }
    """
    
    all_novels = []
    page_num = 1
    
    # ===============================================
    # ğŸ”§ ì—¬ê¸°ì„œ ìµœëŒ€ í˜ì´ì§€ ìˆ˜ì •í•˜ì„¸ìš”!
    # ===============================================
    max_pages = None     # None = ìë™ ê³„ì‚° (ì „ì²´)
    # max_pages = 50     # 50í˜ì´ì§€ë§Œ ìˆ˜ì§‘
    # max_pages = 100    # 100í˜ì´ì§€ë§Œ ìˆ˜ì§‘  
    # max_pages = 500    # 500í˜ì´ì§€ë§Œ ìˆ˜ì§‘
    
    # ì‚¬ìš©ì í™•ì¸ ë°›ì„ ì„ê³„ê°’ (ì´ í˜ì´ì§€ ìˆ˜ ì´ìƒì´ë©´ í™•ì¸ ìš”ì²­)
    confirmation_threshold = 100
    
    failed_requests = 0
    max_failures = 3  # ì—°ì† ì‹¤íŒ¨ í—ˆìš© íšŸìˆ˜
    
    print("ì†Œì„¤ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
    print("âš ï¸  ì•ˆì „í•œ í¬ë¡¤ë§ì„ ìœ„í•´ ê° ìš”ì²­ ì‚¬ì´ì— 2-5ì´ˆì”© ëŒ€ê¸°í•©ë‹ˆë‹¤.")
    
    while (max_pages is None or page_num <= max_pages) and failed_requests < max_failures:
    
    # while page_num <= max_pages:
        variables = {
            "sectionId": "static-landing-Genre-section-Layout-11-0-update-false-84",
            "param": {
                "categoryUid": 11,
                "subcategoryUid": "0",
                "sortType": "update",
                "isComplete": False,
                "screenUid": 84,
                "page": page_num
            }
        }
        
        payload = {
            "query": query,
            "variables": variables
        }
        
        try:
            response = session.post(
                'https://bff-page.kakao.com/graphql',
                json=payload,
                headers=headers,
                timeout=30
            )
            
            # ìƒíƒœ ì½”ë“œ í™•ì¸
            if response.status_code == 429:
                print(f"âš ï¸  Rate limit ê°ì§€. 30ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                time.sleep(30)
                continue
            elif response.status_code == 403:
                print(f"âŒ ì ‘ê·¼ ê±°ë¶€ (403). IP ì°¨ë‹¨ ê°€ëŠ¥ì„±.")
                break
            elif response.status_code != 200:
                print(f"âŒ HTTP {response.status_code} ì˜¤ë¥˜")
                failed_requests += 1
                continue
            
            if response.status_code == 200:
                data = response.json()
                
                # ë””ë²„ê¹…: ì‘ë‹µ êµ¬ì¡° í™•ì¸
                print(f"ì‘ë‹µ í‚¤ë“¤: {list(data.keys()) if isinstance(data, dict) else 'Not dict'}")
                if 'data' in data:
                    print(f"data í‚¤ë“¤: {list(data['data'].keys()) if data['data'] else 'data is None'}")
                
                # ì „ì²´ ì‘ë‹µì„ íŒŒì¼ë¡œ ì €ì¥ (ì²« ë²ˆì§¸ í˜ì´ì§€ë§Œ)
                if page_num == 1:
                    with open(f'debug_response_page_{page_num}.json', 'w', encoding='utf-8') as f:
                        json.dump(data, f, ensure_ascii=False, indent=2)
                    print(f"ë””ë²„ê¹…ìš© ì‘ë‹µì´ debug_response_page_{page_num}.json íŒŒì¼ë¡œ ì €ì¥ë¨")
                
                if 'data' in data and data['data'] and 'staticLandingGenreSection' in data['data']:
                    section = data['data']['staticLandingGenreSection']
                    
                    # ì´ ê°œìˆ˜ í™•ì¸ ë° ìµœëŒ€ í˜ì´ì§€ ê³„ì‚°
                    total_count = section.get('totalCount', 0)
                    is_end = section.get('isEnd', False)
                    
                    # ì²« ë²ˆì§¸ í˜ì´ì§€ì—ì„œ ìµœëŒ€ í˜ì´ì§€ ê³„ì‚°
                    if page_num == 1 and total_count and max_pages is None:
                        items_per_page = 24  # ê´€ì°°ëœ í˜ì´ì§€ë‹¹ ì•„ì´í…œ ìˆ˜
                        import math
                        calculated_max_pages = math.ceil(total_count / items_per_page)
                        print(f"ğŸ“Š ì´ ì†Œì„¤ ê°œìˆ˜: {total_count:,}ê°œ")
                        print(f"ğŸ“Š ì˜ˆìƒ ì´ í˜ì´ì§€: {calculated_max_pages:,}í˜ì´ì§€")
                        print(f"ğŸ“Š ì˜ˆìƒ ì†Œìš”ì‹œê°„: {calculated_max_pages * 3.5 / 60:.1f}ë¶„")
                        
                        # ì‚¬ìš©ì í™•ì¸
                        if calculated_max_pages > confirmation_threshold:
                            user_input = input(f"\nâš ï¸  ì´ {calculated_max_pages}í˜ì´ì§€ë¥¼ ìˆ˜ì§‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n/ìˆ«ì): ")
                            if user_input.lower() == 'n':
                                print("ìˆ˜ì§‘ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                                break
                            elif user_input.isdigit():
                                max_pages = min(int(user_input), calculated_max_pages)
                                print(f"ìµœëŒ€ {max_pages}í˜ì´ì§€ê¹Œì§€ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
                            else:
                                max_pages = calculated_max_pages
                        else:
                            max_pages = calculated_max_pages
                    
                    print(f"í˜ì´ì§€ {page_num}/{max_pages or '?'}: ì´ {total_count}ê°œ ì¤‘ ìˆ˜ì§‘ ì¤‘...")
                    print(f"ì„¹ì…˜ í‚¤ë“¤: {list(section.keys())}")
                    
                    # ì•„ì´í…œë“¤ ì¶”ì¶œ
                    if 'groups' in section:
                        print(f"ê·¸ë£¹ ê°œìˆ˜: {len(section['groups'])}")
                        for group_idx, group in enumerate(section['groups']):
                            print(f"ê·¸ë£¹ {group_idx} í‚¤ë“¤: {list(group.keys())}")
                            if 'items' in group:
                                print(f"ê·¸ë£¹ {group_idx} ì•„ì´í…œ ê°œìˆ˜: {len(group['items'])}")
                                
                                # ì•„ì´í…œ íƒ€ì…ë“¤ í™•ì¸
                                item_types = [item.get('type') for item in group['items']]
                                print(f"ì•„ì´í…œ íƒ€ì…ë“¤: {set(item_types)}")
                                
                                # ì²« ë²ˆì§¸ í˜ì´ì§€ì—ì„œ ìƒ˜í”Œ ì•„ì´í…œ êµ¬ì¡° í™•ì¸
                                if page_num == 1 and group['items']:
                                    print(f"ì²« ë²ˆì§¸ ì•„ì´í…œ í‚¤ë“¤: {list(group['items'][0].keys())}")
                                    print(f"ì²« ë²ˆì§¸ ì•„ì´í…œ ìƒ˜í”Œ: {group['items'][0]}")
                                
                                for item in group['items']:
                                    item_type = item.get('type')
                                    print(f"ì²˜ë¦¬ ì¤‘ì¸ ì•„ì´í…œ íƒ€ì…: {item_type}")
                                    
                                    # ëª¨ë“  íƒ€ì…ì˜ ì•„ì´í…œì„ ì¼ë‹¨ ìˆ˜ì§‘í•´ë³´ì
                                    if item_type and 'title' in item:  # ì œëª©ì´ ìˆëŠ” ëª¨ë“  ì•„ì´í…œ
                                        novel_info = {
                                            'id': item.get('id'),
                                            'title': item.get('title'),
                                            'thumbnail': item.get('thumbnail'),
                                            'scheme': item.get('scheme'),
                                            'subtitleList': item.get('subtitleList', []),
                                            'badgeList': item.get('badgeList', []),
                                            'ageGrade': item.get('ageGrade'),
                                            'rank': item.get('rank'),
                                            'type': item.get('type')
                                        }
                                        all_novels.append(novel_info)
                                        print(f"ì•„ì´í…œ ì¶”ê°€ë¨: {item.get('title', 'No title')}")
                                    else:
                                        print(f"ì•„ì´í…œ ìŠ¤í‚µë¨ - íƒ€ì…: {item_type}, í‚¤ë“¤: {list(item.keys())}")
                    else:
                        print("groups í‚¤ê°€ ì—†ìŒ")
                    
                    print(f"í˜ì´ì§€ {page_num} ì™„ë£Œ. í˜„ì¬ê¹Œì§€ {len(all_novels)}ê°œ ìˆ˜ì§‘ë¨")
                    
                    # ë§ˆì§€ë§‰ í˜ì´ì§€ì¸ì§€ í™•ì¸
                    if is_end:
                        print(f"ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬ (í˜ì´ì§€ {page_num})")
                        break
                    
                    page_num += 1
                    
                    # ì•ˆì „í•œ ìš”ì²­ ê°„ê²© (ëœë¤í•˜ê²Œ 2-5ì´ˆ)
                    import random
                    wait_time = random.uniform(1,3)
                    print(f"ë‹¤ìŒ ìš”ì²­ê¹Œì§€ {wait_time:.1f}ì´ˆ ëŒ€ê¸° ì¤‘...")
                    time.sleep(wait_time)
                    
                else:
                    print(f"í˜ì´ì§€ {page_num}: ë°ì´í„° êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦„")
                    if 'errors' in data:
                        print(f"GraphQL ì˜¤ë¥˜: {data['errors']}")
                    break
                    
            else:
                print(f"ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
                print(f"ì‘ë‹µ: {response.text[:500]}")
                break
                
        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ (í˜ì´ì§€ {page_num}): {e}")
            break
    
    return all_novels

def crawl_novels_with_playwright():
    """playwright ë¸Œë¼ìš°ì € ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ í˜¸ì¶œ"""
    with sync_playwright() as p:
        browser = p.chromium.launch()
        page = browser.new_page()
        
        page.goto('https://page.kakao.com/menu/10011/screen/84')
        page.wait_for_load_state('networkidle')
        
        print("ë¸Œë¼ìš°ì € ì»¨í…ìŠ¤íŠ¸ì—ì„œ GraphQL í˜¸ì¶œ ì‹œì‘...")
        
        all_novels = page.evaluate("""
            async () => {
                const results = [];
                let page_num = 1;
                const max_pages = 50;
                
                const query = `
                    query staticLandingGenreSection($sectionId: ID!, $param: StaticLandingGenreParamInput!) {
                      staticLandingGenreSection(sectionId: $sectionId, param: $param) {
                        isEnd
                        totalCount
                        groups {
                          id
                          type
                          dataKey
                          items {
                            id
                            type
                            ... on PosterViewItem {
                              title
                              thumbnail
                              scheme
                              subtitleList
                              badgeList
                              rank
                            }
                            ... on CardViewItem {
                              title
                              thumbnail
                              scheme
                              subtitleList
                              badgeList
                              rank
                            }
                          }
                        }
                      }
                    }
                `;
                
                while (page_num <= max_pages) {
                    try {
                        const variables = {
                            "sectionId": "static-landing-Genre-section-Layout-11-0-update-false-84",
                            "param": {
                                "categoryUid": 11,
                                "subcategoryUid": "0",
                                "sortType": "update",
                                "isComplete": false,
                                "screenUid": 84,
                                "page": page_num
                            }
                        };
                        
                        const response = await fetch('https://bff-page.kakao.com/graphql', {
                            method: 'POST',
                            headers: {
                                'Content-Type': 'application/json',
                                'Accept': 'application/json'
                            },
                            body: JSON.stringify({
                                query: query,
                                variables: variables
                            })
                        });
                        
                        const data = await response.json();
                        
                        if (data.data && data.data.staticLandingGenreSection) {
                            const section = data.data.staticLandingGenreSection;
                            
                            console.log(`í˜ì´ì§€ ${page_num}: ì´ ${section.totalCount}ê°œ`);
                            
                            if (section.groups) {
                                for (const group of section.groups) {
                                    if (group.items) {
                                        for (const item of group.items) {
                                            if (item.type === 'PosterViewItem' || item.type === 'CardViewItem') {
                                                results.push({
                                                    id: item.id,
                                                    title: item.title,
                                                    thumbnail: item.thumbnail,
                                                    scheme: item.scheme,
                                                    subtitleList: item.subtitleList || [],
                                                    badgeList: item.badgeList || [],
                                                    rank: item.rank,
                                                    type: item.type
                                                });
                                            }
                                        }
                                    }
                                }
                            }
                            
                            console.log(`í˜ì´ì§€ ${page_num} ì™„ë£Œ. í˜„ì¬ê¹Œì§€ ${results.length}ê°œ ìˆ˜ì§‘`);
                            
                            if (section.isEnd) {
                                console.log(`ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬`);
                                break;
                            }
                            
                            page_num++;
                            
                            // ì ê¹ ëŒ€ê¸°
                            await new Promise(resolve => setTimeout(resolve, 500));
                        } else {
                            console.log(`í˜ì´ì§€ ${page_num}: ë°ì´í„° ì—†ìŒ`);
                            break;
                        }
                        
                    } catch (error) {
                        console.error(`í˜ì´ì§€ ${page_num} ì˜¤ë¥˜:`, error);
                        break;
                    }
                }
                
                return results;
            }
        """)
        
        browser.close()
        return all_novels

def save_novels_to_file(novels, filename='kakao_novels.json'):
    """ì†Œì„¤ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    with open('data/'+filename, 'w', encoding='utf-8') as f:
        json.dump(novels, f, ensure_ascii=False, indent=2)
    print(f"ê²°ê³¼ê°€ '{filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ë°ì´í„° ë‚˜ëˆ„ê¸°
def split_data(data, split_num):
    """ë¦¬ìŠ¤íŠ¸ì™€ ë”•ì…”ë„ˆë¦¬ ëª¨ë‘ ì²˜ë¦¬í•˜ëŠ” ë²”ìš© ë¶„í•  í•¨ìˆ˜"""
    
    if isinstance(data, list):
        # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° (ê¸°ì¡´ ë¡œì§)
        new_data = []
        for i in range(0, len(data), split_num):
            new_data.append(data[i: i+split_num])
        return new_data
    
    elif isinstance(data, dict):
        # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°
        items = list(data.items())  # (key, value) íŠœí”Œë“¤ì˜ ë¦¬ìŠ¤íŠ¸
        new_data = []
        
        for i in range(0, len(items), split_num):
            batch_items = items[i: i+split_num]
            batch_dict = dict(batch_items)  # ë‹¤ì‹œ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            new_data.append(batch_dict)
        
        return new_data
    
    else:
        raise TypeError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íƒ€ì…ì…ë‹ˆë‹¤: {type(data)}")

# ì†Œì„¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
async def crawl_data(playwright, url, user_agent, age='All'):
    if age == '19':
        # 19ê¸ˆ ì¸ ê²½ìš°ì— ë¡œê·¸ì¸í•˜ê¸°
        pass
    try:
        # print(url)
        browser = await playwright.chromium.launch(
            headless=True,
            args=[
                '--no-sandbox',
                '--disable-dev-shm-usage',
                '--disable-blink-features=AutomationControlled',
                '--disable-web-security',
                '--disable-features=VizDisplayCompositor',
                '--no-first-run',
                '--disable-extensions',
                '--disable-default-apps',
                '--disable-gpu'
            ]
        )
        context = await browser.new_context(
            user_agent=user_agent,
            is_mobile=False,
            has_touch=False,
            viewport={'width': 1920, 'height': 1080}
        )
        page = await context.new_page()
        
        await page.goto(url)
        await page.wait_for_load_state('networkidle')
        # time.sleep(100)
        
        # print("ë¸Œë¼ìš°ì € ì»¨í…ìŠ¤íŠ¸ì—ì„œ GraphQL í˜¸ì¶œ ì‹œì‘...")
        
        img_xpaths = [
            'xpath=//*[@id="__next"]/div/div[2]/div[1]/div/div[1]/div[1]/div/div[1]/div[2]/div/div/div/img',
            # 'xpath=//*[@id="__next"]/div/div[2]/div[1]/div/div[1]/div[1]/div/div[1]/div[2]/div/div/div[2]/img',
        ]
        # for xpath in img_xpaths:
        # ê°œì„ ëœ ë°©ë²•
        img_locator = page.locator('xpath=//*[@id="__next"]/div/div[2]/div[1]/div/div[1]/div[1]/div/div[1]/div[2]/div/div/div/img')
        if await img_locator.count() > 1:
            img = await img_locator.last.get_attribute('src')
        else:
            img = await img_locator.first.get_attribute('src')  # ë˜ëŠ” ê·¸ëƒ¥ img_locator.get_attribute('src')
        
        title = await page.locator('xpath=//*[@id="__next"]/div/div[2]/div[1]/div/div[1]/div[1]/div/div[2]/a/div/span[1]').inner_text()
        author = await page.locator('xpath=//*[@id="__next"]/div/div[2]/div[1]/div/div[1]/div[1]/div/div[2]/a/div/span[2]').inner_text()
        if await page.locator('xpath=//*[@id="__next"]/div/div[2]/div[1]/div/div[1]/div[1]/div/div[2]/a/div/div[1]/div[3]/span').count() > 0:
            rating = await page.locator('xpath=//*[@id="__next"]/div/div[2]/div[1]/div/div[1]/div[1]/div/div[2]/a/div/div[1]/div[3]/span').inner_text()
        else:
            rating = None
        genre = await page.locator('xpath=//*[@id="__next"]/div/div[2]/div[1]/div/div[1]/div[1]/div/div[2]/a/div/div[1]/div[1]/div').inner_text()
        serial = await page.locator('xpath=//*[@id="__next"]/div/div[2]/div[1]/div/div[1]/div[1]/div/div[2]/a/div/div[2]/span').inner_text()
        publisher = await page.locator('xpath=//*[@id="__next"]/div/div[2]/div[1]/div/div[1]/div[1]/div/div[2]/a/div/span[2]').inner_text()

        page_count = await page.locator('xpath=//*[@id="__next"]/div/div[2]/div[1]/div/div[2]/div[2]/div[1]/div[1]/div[1]/span').inner_text()

        if 'ë‹¨í–‰ë³¸' in title:
            page_unit = 'ê¶Œ'
        else:
            page_unit = 'í™”'
        
        if '19ì„¸ ì™„ì „íŒ' in title:
            age = '19'
        else:
            age = 'ì „ì²´'
        # age = page.locator('xpath=//*[@id="__next"]/div/div[2]/div[1]/div/div[1]/div[1]/div/div[2]/a/div/span[2]').inner_text()

        viewers = await page.locator('xpath=//*[@id="__next"]/div/div[2]/div[1]/div/div[1]/div[1]/div/div[2]/a/div/div[1]/div[2]/span').inner_text()

        # ì •ë³´ ë³´ê¸°
        await page.locator('xpath=//*[@id="__next"]/div/div[2]/div[1]/div/div[2]/div[1]/div/div/div[2]/a').click()
        await page.wait_for_selector('xpath=//*[@id="__next"]/div/div[2]/div[1]/div/div[2]/div[2]/div/div/div[1]/div/div[2]/div/div[1]/span')
        await asyncio.sleep(.5)
        summary = await page.locator('xpath=//*[@id="__next"]/div/div[2]/div[1]/div/div[2]/div[2]/div/div/div[1]/div/div[2]/div/div[1]/span').inner_text()
        
        if await page.locator('xpath=//*[@id="__next"]/div/div[2]/div[1]/div/div[2]/div[2]/div/div/div[2]/div[2]/div').count() == 1:
            keywords = page.locator('xpath=//*[@id="__next"]/div/div[2]/div[1]/div/div[2]/div[2]/div/div/div[2]/div[2]/div').inner_text()
        elif await page.locator('xpath=//*[@id="__next"]/div/div[2]/div[1]/div/div[2]/div[2]/div/div/div[2]/div[2]/div').count() > 1:
            keywords = page.locator('xpath=//*[@id="__next"]/div/div[2]/div[1]/div/div[2]/div[2]/div/div/div[2]/div[2]/div').last.inner_text()
        else:
             keywords = ''

        
        novel_data = {
            'url': url,
            'img': img,
            'title': title,
            'author': author,
            'rating': rating,
            'genre': genre,
            'serial': serial,
            'publisher': publisher,
            'summary': summary,
            'page_count': page_count,
            'page_unit': page_unit,
            'age': age,
            'platform': 'kakao',
            'keywords': keywords,
            'viewers': viewers
        }
        await asyncio.sleep(random.uniform(1, 2))
        # time.sleep(100)
        return novel_data
        
    except Exception as e:
        print(f"[ERROR] {url}")
        print(e)
    finally:
        if browser:
            try:
                await browser.close()
            except:
                pass

async def save_data(data):
    df = pd.DataFrame(data)
    df.to_csv('data/kakao_novel_data.csv', encoding='utf-8', index=False)
    print('ë°ì´í„° ì €ì¥')

async def main():
    if os.path.exists('data/kakao_novels.json'):
        with open('data/kakao_novels.json', 'r') as f:
            datas = json.load(f)
    else:
        print("=== ì¹´ì¹´ì˜¤í˜ì´ì§€ ì†Œì„¤ í¬ë¡¤ë§ (ìŠ¤í¬ë¡¤ ì—†ì´) ===")
        print()
        
        method = input("í¬ë¡¤ë§ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš” (1: requests, 2: playwright): ")
        
        if method == "1":
            novels = crawl_novels_with_requests()
        else:
            novels = crawl_novels_with_playwright()
        
        print(f"\n=== ìˆ˜ì§‘ ì™„ë£Œ ===")
        print(f"ì´ {len(novels)}ê°œì˜ ì†Œì„¤ ì •ë³´ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
        
        if novels:
            # ê²°ê³¼ ìƒ˜í”Œ ì¶œë ¥
            print("\n=== ìˆ˜ì§‘ëœ ë°ì´í„° ìƒ˜í”Œ ===")
            for i, novel in enumerate(novels[:5]):
                print(f"{i+1}. {novel.get('title', 'N/A')}")
                if novel.get('subtitleList'):
                    print(f"   ì‘ê°€: {', '.join(novel['subtitleList'])}")
                print(f"   ID: {novel.get('id', 'N/A')}")
                print()
            
            # íŒŒì¼ë¡œ ì €ì¥
            save_novels_to_file(novels)
            
            # í†µê³„ ì¶œë ¥
            print("=== í†µê³„ ===")
            print(f"PosterViewItem: {len([n for n in novels if n.get('type') == 'PosterViewItem'])}ê°œ")
            print(f"CardViewItem: {len([n for n in novels if n.get('type') == 'CardViewItem'])}ê°œ")
            
            # ë­í‚¹ì´ ìˆëŠ” ì‘í’ˆë“¤
            ranked_novels = [n for n in novels if n.get('rank')]
            if ranked_novels:
                print(f"ë­í‚¹ ì •ë³´ê°€ ìˆëŠ” ì‘í’ˆ: {len(ranked_novels)}ê°œ")
        datas = novels.copy()


    ua = UserAgent(platforms='desktop')
    not_nineteen_links = []
    nineteen_links = []
    for data in datas:
        # 19ê¸ˆ ë¶„ë¦¬
        if data['ageGrade'] != 'Nineteen':
            link = data['scheme'].replace('kakaopage://open/', 'https://page.kakao.com/')
            link = link.replace('?series_id=', '/')
            link += '?tab_type=overview'
            not_nineteen_links.append(link)
        else:
            nineteen_links.append(link)

    # ì „ì²´ ì´ìš©ê°€ í¬ë¡¤ë§
    not_nineteen_links = split_data(not_nineteen_links, 5)
    all_results = []
    async with async_playwright() as playwright:
        # ë§í¬ ìˆ˜ì§‘ ì§„í–‰ìƒí™© í‘œì‹œ
        for url_list in tqdm(not_nineteen_links, desc="ğŸ“„ í˜ì´ì§€ë³„ ë§í¬ ìˆ˜ì§‘", unit="ë°°ì¹˜"):
            tasks = [crawl_data(playwright, url, ua.random, age='all') for url in url_list]
            
            # tqdm_asyncioë¡œ ê° ë°°ì¹˜ ë‚´ íƒœìŠ¤í¬ ì§„í–‰ìƒí™© í‘œì‹œ
            batch_results = await tqdm_asyncio.gather(
                *tasks, 
                desc=f"URL ì²˜ë¦¬ ({len(url_list)}ê°œ)", 
                unit="í˜ì´ì§€",
                # return_exceptions=True
            )
            all_results.append(batch_results)

    # 19ê¸ˆ ì‘í’ˆ í¬ë¡¤ë§
    nineteen_links = split_data(nineteen_links, 5)
    async with async_playwright() as playwright:
        # ë§í¬ ìˆ˜ì§‘ ì§„í–‰ìƒí™© í‘œì‹œ
        for url_list in tqdm(nineteen_links, desc="ğŸ“„ í˜ì´ì§€ë³„ ë§í¬ ìˆ˜ì§‘", unit="ë°°ì¹˜"):
            tasks = [crawl_data(playwright, url, ua.random, age='19') for url in url_list]
            
            # tqdm_asyncioë¡œ ê° ë°°ì¹˜ ë‚´ íƒœìŠ¤í¬ ì§„í–‰ìƒí™© í‘œì‹œ
            batch_results = await tqdm_asyncio.gather(
                *tasks, 
                desc=f"URL ì²˜ë¦¬ ({len(url_list)}ê°œ)", 
                unit="í˜ì´ì§€",
                # return_exceptions=True
            )
            all_results.append(batch_results)

    all_results = list(chain.from_iterable(all_results))

    await save_data(all_results)




if __name__ == "__main__":
    asyncio.run(main())